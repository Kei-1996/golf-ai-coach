import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import av
import tempfile
import pandas as pd
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode

# --- 1. åŸºæœ¬è¨­å®š ---
st.set_page_config(layout="wide", page_title="K's Golf AI Coach")

st.markdown("""
    <style>
    .main > div {padding-top: 2rem;}
    video { width: 100% !important; height: auto !important; }
    .stMetric { background-color: #f0f2f6; padding: 10px; border-radius: 5px; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# --- Session State ---
if 'pro_processed_video' not in st.session_state: st.session_state['pro_processed_video'] = None
if 'pro_df' not in st.session_state: st.session_state['pro_df'] = None
if 'my_processed_video' not in st.session_state: st.session_state['my_processed_video'] = None
if 'my_df' not in st.session_state: st.session_state['my_df'] = None
if 'sync_video_path' not in st.session_state: st.session_state['sync_video_path'] = None
if 'pro_fps' not in st.session_state: st.session_state['pro_fps'] = 30
if 'my_fps' not in st.session_state: st.session_state['my_fps'] = 30

# --- 2. è¨ˆç®—ãƒ»è§£æç”¨é–¢æ•° ---

def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0: angle = 360-angle
    return angle

def analyze_video(input_path, output_path):
    """å‹•ç”»è§£æï¼šè‚˜ã€é¼»(é ­)ã€æ‰‹é¦–Y(é«˜ã•)ã‚’è¨˜éŒ²"""
    cap = cv2.VideoCapture(input_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    pose_data = []
    
    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        bar = st.progress(0)
        for i in range(frame_count):
            ret, frame = cap.read()
            if not ret: break
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                
                # åº§æ¨™å–å¾—
                l_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                l_elbow    = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                l_wrist    = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]
                nose       = [landmarks[mp_pose.PoseLandmark.NOSE.value].x, landmarks[mp_pose.PoseLandmark.NOSE.value].y]
                
                angle = calculate_angle(l_shoulder, l_elbow, l_wrist)
                
                pose_data.append({
                    "Frame": i,
                    "Time": i / fps if fps > 0 else 0,
                    "Arm_Angle": angle,
                    "L_Wrist_Y": l_wrist[1], # Yåº§æ¨™: å°ã•ã„=é«˜ã„ã€å¤§ãã„=ä½ã„
                    "Nose_X": nose[0]        # ã‚¹ã‚¦ã‚§ã‚¤åˆ¤å®šç”¨
                })

                # æç”»
                color = (0, 255, 0) if angle > 160 else (0, 0, 255)
                mp_drawing.draw_landmarks(
                    image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=4),
                    mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2)
                )
                
                # é ­ã®ä½ç½®ã‚’ãƒãƒ¼ã‚¯
                h, w, _ = image.shape
                cv2.circle(image, (int(nose[0]*w), int(nose[1]*h)), 5, (255, 255, 0), -1)

            out.write(image)
            if frame_count > 0: bar.progress((i + 1) / frame_count)

    cap.release()
    out.release()
    df = pd.DataFrame(pose_data)
    return output_path, df, fps

def create_sync_video(pro_path, my_path, pro_top_frame, my_top_frame, output_path, target_fps):
    """åŒæœŸå‹•ç”»ç”Ÿæˆï¼ˆãƒˆãƒƒãƒ—ä½ç½®åˆã‚ã›ï¼‰"""
    cap_pro = cv2.VideoCapture(pro_path)
    cap_my = cv2.VideoCapture(my_path)

    # é«˜ã•åˆã‚ã›
    h_pro = int(cap_pro.get(cv2.CAP_PROP_FRAME_HEIGHT))
    h_my = int(cap_my.get(cv2.CAP_PROP_FRAME_HEIGHT))
    target_h = min(h_pro, h_my)
    
    w_pro = int(cap_pro.get(cv2.CAP_PROP_FRAME_WIDTH))
    w_my = int(cap_my.get(cv2.CAP_PROP_FRAME_WIDTH))
    new_w_pro = int(w_pro * (target_h / h_pro))
    new_w_my = int(w_my * (target_h / h_my))
    target_w = new_w_pro + new_w_my

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, target_fps, (target_w, target_h))

    offset = my_top_frame - pro_top_frame
    pro_delay = max(0, offset)
    my_delay = max(0, -offset)
    
    max_frames = int(max(cap_pro.get(cv2.CAP_PROP_FRAME_COUNT) + pro_delay, 
                         cap_my.get(cv2.CAP_PROP_FRAME_COUNT) + my_delay))

    bar = st.progress(0)
    sync_text = "Syncing..."

    for i in range(max_frames):
        if i < pro_delay:
            cap_pro.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret_pro, frame_pro = cap_pro.read()
            sync_text = "Waiting for Pro..."
        else:
            ret_pro, frame_pro = cap_pro.read()
        
        if i < my_delay:
            cap_my.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret_my, frame_my = cap_my.read()
            sync_text = "Waiting for You..."
        else:
            ret_my, frame_my = cap_my.read()
            
        if not ret_pro or not ret_my: break

        frame_pro_resized = cv2.resize(frame_pro, (new_w_pro, target_h))
        frame_my_resized = cv2.resize(frame_my, (new_w_my, target_h))
        concat_frame = cv2.hconcat([frame_pro_resized, frame_my_resized])
        
        if i == (pro_top_frame + pro_delay): sync_text = "TOP POSITION MATCHED!"
        cv2.putText(concat_frame, sync_text, (target_w//2 - 120, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)
        
        out.write(concat_frame)
        bar.progress((i + 1) / max_frames)

    cap_pro.release()
    cap_my.release()
    out.release()
    return output_path

# --- 3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ ---
class PoseProcessor(VideoProcessorBase):
    def __init__(self):
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.pose.process(image)
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        if results.pose_landmarks:
            self.mp_drawing.draw_landmarks(image, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)
        return av.VideoFrame.from_ndarray(image, format="bgr24")

# --- 4. ã‚¢ãƒ—ãƒªãƒ¡ã‚¤ãƒ³ ---
st.title("â›³ï¸ K's Golf AI Coach")
st.sidebar.header("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
app_mode = st.sidebar.selectbox("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š (Real-time)", "å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ†æ (Upload)"])
st.sidebar.divider()
club_select = st.sidebar.selectbox("ä½¿ç”¨ã‚¯ãƒ©ãƒ–", ["ãƒ‰ãƒ©ã‚¤ãƒãƒ¼", "ã‚¢ã‚¤ã‚¢ãƒ³", "ã‚¦ã‚§ãƒƒã‚¸", "ãƒ‘ã‚¿ãƒ¼"])

# --- ãƒ¢ãƒ¼ãƒ‰A ---
if app_mode == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š (Real-time)":
    st.header("âš¡ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ã‚³ãƒ¼ãƒ")
    col1, col2 = st.columns(2)
    with col1:
        st.info("ğŸ‘ˆ ãƒ—ãƒ­ã®ãŠæ‰‹æœ¬")
        st.image("https://via.placeholder.com/360x640.png?text=Pro+Swing", use_container_width=True)
    with col2:
        st.success("ğŸ“¸ ã‚«ãƒ¡ãƒ©æ˜ åƒ")
        webrtc_streamer(key="golf-realtime", mode=WebRtcMode.SENDRECV, video_processor_factory=PoseProcessor)

# --- ãƒ¢ãƒ¼ãƒ‰B ---
elif app_mode == "å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ†æ (Upload)":
    st.header("ğŸ“‚ å‹•ç”»åˆ†æãƒ©ãƒœ")
    st.warning("âš ï¸ **é‡è¦:** æ­£ç¢ºãªæ¯”è¼ƒã®ãŸã‚ã€**ãƒ—ãƒ­ã®å‹•ç”»ã¨ã€ŒåŒã˜ã‚¢ãƒ³ã‚°ãƒ«ã€** ã§æ’®å½±ã•ã‚ŒãŸå‹•ç”»ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
    
    col1, col2 = st.columns(2)

    # ãƒ—ãƒ­å‹•ç”»
    with col1:
        st.subheader("1. ãƒ—ãƒ­/ãŠæ‰‹æœ¬ã®å‹•ç”»")
        pro_video = st.file_uploader("ãƒ—ãƒ­ã®å‹•ç”»", type=['mp4', 'mov'], key="pro_video")
        if pro_video is not None:
            if st.button("ğŸ” ãƒ—ãƒ­è§£æ"):
                tfile = tempfile.NamedTemporaryFile(delete=False)
                tfile.write(pro_video.read())
                with st.spinner("ãƒ—ãƒ­è§£æä¸­..."):
                    path, df, fps = analyze_video(tfile.name, tfile.name + "_pro.mp4")
                    st.session_state['pro_processed_video'] = path
                    st.session_state['pro_df'] = df
                    st.session_state['pro_fps'] = fps
                    st.success("å®Œäº†")
            if st.session_state['pro_processed_video']:
                st.video(st.session_state['pro_processed_video'])

    # è‡ªåˆ†å‹•ç”»
    with col2:
        st.subheader("2. ã‚ãªãŸã®ã‚¹ã‚¤ãƒ³ã‚°å‹•ç”»")
        my_video = st.file_uploader("è‡ªåˆ†ã®å‹•ç”»", type=['mp4', 'mov'], key="my_video")
        if my_video is not None:
            if st.button("ğŸš€ è‡ªåˆ†è§£æ"):
                tfile = tempfile.NamedTemporaryFile(delete=False)
                tfile.write(my_video.read())
                with st.spinner("è‡ªåˆ†è§£æä¸­..."):
                    path, df, fps = analyze_video(tfile.name, tfile.name + "_my.mp4")
                    st.session_state['my_processed_video'] = path
                    st.session_state['my_df'] = df
                    st.session_state['my_fps'] = fps
                    st.success("å®Œäº†")
            if st.session_state['my_processed_video']:
                st.video(st.session_state['my_processed_video'])

    # --- ç·åˆè©•ä¾¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
    if st.session_state['pro_df'] is not None and st.session_state['my_df'] is not None:
        st.divider()
        st.header("ğŸ“Š ç·åˆã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­")
        
        pro_df = st.session_state['pro_df']
        my_df = st.session_state['my_df']
        
        # --- 1. ãƒˆãƒƒãƒ—æ¤œå‡º (ä¸€ç•ªæ‰‹ãŒä¸ŠãŒã£ãŸç¬é–“) ---
        pro_top_idx = pro_df['L_Wrist_Y'].idxmin()
        my_top_idx = my_df['L_Wrist_Y'].idxmin()
        
        # --- 2. ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¤œå‡º (ãƒˆãƒƒãƒ—ã®å¾Œã«ã€æ‰‹ãŒä¸€ç•ªä¸‹ãŒã£ãŸç¬é–“) ---
        # ãƒ—ãƒ­
        pro_after_top = pro_df.iloc[pro_top_idx:] # ãƒˆãƒƒãƒ—ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿
        if not pro_after_top.empty:
            pro_impact_idx = pro_after_top['L_Wrist_Y'].idxmax() # ä¸€ç•ªä¸‹ãŒã£ãŸä½ç½®(Yæœ€å¤§)
        else:
            pro_impact_idx = pro_top_idx # ã‚¨ãƒ©ãƒ¼å›é¿

        # è‡ªåˆ†
        my_after_top = my_df.iloc[my_top_idx:]
        if not my_after_top.empty:
            my_impact_idx = my_after_top['L_Wrist_Y'].idxmax()
        else:
            my_impact_idx = my_top_idx

        # --- ã‚¹ã‚³ã‚¢è¨ˆç®— ---
        
        # â‘  è‚˜ã®è§’åº¦ (ãƒˆãƒƒãƒ—æ™‚)
        pro_arm = pro_df.iloc[pro_top_idx]['Arm_Angle']
        my_arm = my_df.iloc[my_top_idx]['Arm_Angle']
        diff_arm = abs(my_arm - pro_arm)
        score_arm = max(0, 100 - diff_arm * 2)

        # â‘¡ é ­ã®å®‰å®šæ€§ (å…¨æœŸé–“ã®æ¨™æº–åå·®)
        pro_sway = pro_df['Nose_X'].std() * 100
        my_sway = my_df['Nose_X'].std() * 100
        diff_sway = max(0, my_sway - pro_sway)
        score_sway = max(0, 100 - diff_sway * 10)

        # â‘¢ ãƒ€ã‚¦ãƒ³ã‚¹ã‚¤ãƒ³ã‚°ãƒ»ãƒ†ãƒ³ãƒ (ãƒˆãƒƒãƒ—ã€œã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®æ™‚é–“)
        pro_down_time = pro_df.iloc[pro_impact_idx]['Time'] - pro_df.iloc[pro_top_idx]['Time']
        my_down_time = my_df.iloc[my_impact_idx]['Time'] - my_df.iloc[my_top_idx]['Time']
        diff_time = abs(my_down_time - pro_down_time)
        # 0.1ç§’ã‚ºãƒ¬ã‚‹ã”ã¨ã«20ç‚¹æ¸›ç‚¹ (ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¯ã‚·ãƒ“ã‚¢ã«)
        score_tempo = max(0, 100 - (diff_time * 100 * 2))

        # ç·åˆç‚¹
        total_score = int((score_arm + score_sway + score_tempo) / 3)

        # --- è¡¨ç¤º ---
        st.subheader(f"ğŸ† ç·åˆã‚¹ã‚³ã‚¢: {total_score}ç‚¹")
        
        c1, c2, c3 = st.columns(3)
        c1.metric("â‘  ãƒˆãƒƒãƒ—ã®å½¢(è‚˜)", f"{int(score_arm)}ç‚¹", f"è§’åº¦å·®: {int(diff_arm)}Â°")
        c2.metric("â‘¡ é ­ã®å®‰å®šæ€§", f"{int(score_sway)}ç‚¹", f"ãƒ–ãƒ¬å·®: {diff_sway:.1f}")
        c3.metric("â‘¢ ã‚¹ã‚¤ãƒ³ã‚°ãƒ†ãƒ³ãƒ", f"{int(score_tempo)}ç‚¹", f"æ™‚é–“å·®: {diff_time:.2f}ç§’")
        
        st.caption(f"ãƒ—ãƒ­ã®ãƒ€ã‚¦ãƒ³ã‚¹ã‚¤ãƒ³ã‚°æ™‚é–“: {pro_down_time:.2f}ç§’ / ã‚ãªãŸ: {my_down_time:.2f}ç§’")

        # --- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ ---
        with st.expander("ğŸ’¡ AIã‚³ãƒ¼ãƒã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹", expanded=True):
            if score_tempo < 80:
                if my_down_time > pro_down_time:
                    st.write("âŒ **ãƒ†ãƒ³ãƒ**: ãƒ—ãƒ­ã‚ˆã‚Šã‚¹ã‚¤ãƒ³ã‚°ãŒã‚†ã£ãã‚Šã§ã™ã€‚æ€ã„åˆ‡ã£ã¦æŒ¯ã‚ŠæŠœãã¾ã—ã‚‡ã†ï¼")
                else:
                    st.write("âŒ **ãƒ†ãƒ³ãƒ**: ãƒ—ãƒ­ã‚ˆã‚Šé€Ÿã™ãã¾ã™ï¼ˆæ‰“ã¡æ€¥ãï¼‰ã€‚ãƒˆãƒƒãƒ—ã§ä¸€ç¬ã€Œé–“ã€ã‚’ä½œã‚‹ã¨å®‰å®šã—ã¾ã™ã€‚")
            else:
                st.write("âœ… **ãƒ†ãƒ³ãƒ**: ç´ æ™´ã‚‰ã—ã„ãƒªã‚ºãƒ ã§ã™ï¼ãƒ—ãƒ­ä¸¦ã¿ã®ã‚­ãƒ¬ãŒã‚ã‚Šã¾ã™ã€‚")

        # --- åŒæœŸå‹•ç”»ç”Ÿæˆ ---
        st.divider()
        st.subheader("ğŸ¬ ãƒ•ã‚©ãƒ¼ãƒ æ¯”è¼ƒ (åŒæœŸå†ç”Ÿ)")
        if st.button("âœ¨ åŒæœŸæ¯”è¼ƒå‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹"):
            with st.spinner("ç”Ÿæˆä¸­..."):
                tfile_sync = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                target_fps = min(st.session_state['pro_fps'], st.session_state['my_fps'])
                create_sync_video(
                    st.session_state['pro_processed_video'],
                    st.session_state['my_processed_video'],
                    pro_df.iloc[pro_top_idx]['Frame'],
                    my_df.iloc[my_top_idx]['Frame'],
                    tfile_sync.name,
                    target_fps
                )
                st.session_state['sync_video_path'] = tfile_sync.name
                st.success("ç”Ÿæˆå®Œäº†")

        if st.session_state['sync_video_path']:
            st.video(st.session_state['sync_video_path'])
