import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import tempfile
import av
from streamlit_webrtc import webrtc_streamer, WebRtcMode, VideoProcessorBase

# --- 1. åŸºæœ¬è¨­å®š & ãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ  ---
st.set_page_config(layout="wide", page_title="K's Golf AI Coach")

# æ—¥æœ¬èªå¯¾å¿œã®ãƒŸãƒ‹ãƒãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³CSS
st.markdown("""
    <style>
    /* æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š (ãƒ’ãƒ©ã‚®ãƒ, ãƒ¡ã‚¤ãƒªã‚ª, æ¸¸ã‚´ã‚·ãƒƒã‚¯) */
    html, body, [class*="css"] {
        font-family: "Hiragino Kaku Gothic ProN", "Hiragino Sans", "Meiryo", "Yu Gothic", sans-serif;
        color: #333333;
    }
    
    .main > div { padding-top: 2rem; }

    /* ãƒ“ãƒ‡ã‚ªè¡¨ç¤º */
    video { 
        width: 100% !important; 
        height: auto !important; 
        border-radius: 12px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    
    /* --- ã‚«ãƒ¼ãƒ‰ãƒ‡ã‚¶ã‚¤ãƒ³ --- */
    .minimal-card {
        background-color: #ffffff;
        border: 1px solid #f0f0f0;
        border-radius: 16px;
        padding: 20px;
        margin-bottom: 20px;
        box-shadow: 0 4px 16px rgba(0,0,0,0.05);
        text-align: center;
    }
    
    .score-title {
        font-size: 0.85rem;
        color: #888888;
        font-weight: 600;
        margin-bottom: 5px;
    }
    
    .total-score-val {
        font-size: 3.5rem;
        font-weight: 700;
        color: #333;
        line-height: 1.0;
        margin-bottom: 10px;
    }
    
    .metric-val {
        font-size: 1.4rem;
        font-weight: 700;
        color: #333;
    }
    
    .advice-text {
        font-size: 0.85rem;
        color: #666;
        margin-top: 5px;
        line-height: 1.4;
    }

    /* --- æ³¨æ„æ›¸ããƒ»Infoãƒ‡ã‚¶ã‚¤ãƒ³ --- */
    .info-box {
        background-color: #f8f9fa;
        border-left: 4px solid #007AFF;
        padding: 15px;
        border-radius: 0 8px 8px 0;
        margin: 15px 0;
        color: #444;
        font-size: 0.9rem;
    }
    
    .warning-box {
        background-color: #fff5f5;
        border-left: 4px solid #FF3B30;
        padding: 15px;
        border-radius: 0 8px 8px 0;
        margin: 15px 0;
        color: #c0392b;
        font-size: 0.9rem;
        font-weight: 600;
    }

    /* --- ãƒœã‚¿ãƒ³ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º --- */
    div.stButton > button {
        border-radius: 8px;
        font-weight: 600;
        border: 1px solid #e0e0e0;
        background-color: #ffffff;
        color: #333;
        transition: all 0.2s;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    div.stButton > button:hover {
        border-color: #007AFF;
        color: #007AFF;
        background-color: #f0f7ff;
        transform: translateY(-1px);
    }
    </style>
    """, unsafe_allow_html=True)

# --- Session State ---
if 'club_data' not in st.session_state: st.session_state['club_data'] = {}
if 'my_processed_video' not in st.session_state: st.session_state['my_processed_video'] = None
if 'my_df' not in st.session_state: st.session_state['my_df'] = None
if 'my_metrics' not in st.session_state: st.session_state['my_metrics'] = None
if 'sync_video_path' not in st.session_state: st.session_state['sync_video_path'] = None

# --- 2. è¨ˆç®—ãƒ»è§£æç”¨é–¢æ•° ---

def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0: angle = 360-angle
    return angle

def get_vertical_angle(a, b):
    a = np.array(a)
    b = np.array(b)
    radians = np.arctan2(abs(a[0]-b[0]), abs(a[1]-b[1]))
    angle = np.abs(radians*180.0/np.pi)
    return angle

def analyze_video_advanced(input_path, output_path, rotate_mode="ãªã—"):
    cap = cv2.VideoCapture(input_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if rotate_mode in ["æ™‚è¨ˆå›ã‚Šã«90åº¦", "åæ™‚è¨ˆå›ã‚Šã«90åº¦"]:
        out_width, out_height = height, width
    else:
        out_width, out_height = width, height
        
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (out_width, out_height))
    
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    # ç·šã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«
    drawing_spec_points = mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2, circle_radius=3)
    drawing_spec_lines = mp_drawing.DrawingSpec(color=(220, 220, 220), thickness=2)

    pose_data = []
    nose_x_list = []
    
    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        bar = st.progress(0)
        for i in range(frame_count):
            ret, frame = cap.read()
            if not ret: break
            
            if rotate_mode == "æ™‚è¨ˆå›ã‚Šã«90åº¦": frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
            elif rotate_mode == "åæ™‚è¨ˆå›ã‚Šã«90åº¦": frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            frame_data = {"Frame": i, "Time": i/fps if fps>0 else 0, "L_Wrist_Y": None}

            if results.pose_landmarks:
                lm = results.pose_landmarks.landmark
                
                nose = [lm[mp_pose.PoseLandmark.NOSE].x, lm[mp_pose.PoseLandmark.NOSE].y]
                l_shoulder = [lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x, lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y]
                l_elbow = [lm[mp_pose.PoseLandmark.LEFT_ELBOW].x, lm[mp_pose.PoseLandmark.LEFT_ELBOW].y]
                l_wrist = [lm[mp_pose.PoseLandmark.LEFT_WRIST].x, lm[mp_pose.PoseLandmark.LEFT_WRIST].y]
                l_hip = [lm[mp_pose.PoseLandmark.LEFT_HIP].x, lm[mp_pose.PoseLandmark.LEFT_HIP].y]
                r_hip = [lm[mp_pose.PoseLandmark.RIGHT_HIP].x, lm[mp_pose.PoseLandmark.RIGHT_HIP].y]
                r_knee = [lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE].y]
                r_ankle = [lm[mp_pose.PoseLandmark.RIGHT_ANKLE].x, lm[mp_pose.PoseLandmark.RIGHT_ANKLE].y]

                arm_angle = calculate_angle(l_shoulder, l_elbow, l_wrist)
                spine_angle = get_vertical_angle(l_shoulder, l_hip)
                knee_angle = calculate_angle(r_hip, r_knee, r_ankle)

                frame_data.update({
                    "L_Wrist_Y": l_wrist[1],
                    "Arm_Angle": arm_angle,
                    "Spine_Angle": spine_angle,
                    "R_Knee_Angle": knee_angle,
                    "Nose_X": nose[0]
                })
                nose_x_list.append(nose[0])
                
                mp_drawing.draw_landmarks(
                    image, 
                    results.pose_landmarks, 
                    mp_pose.POSE_CONNECTIONS,
                    landmark_drawing_spec=drawing_spec_points,
                    connection_drawing_spec=drawing_spec_lines
                )

            pose_data.append(frame_data)
            out.write(image)
            if frame_count > 0: bar.progress((i + 1) / frame_count)

    cap.release()
    out.release()
    df = pd.DataFrame(pose_data)
    
    if not df.empty and df['L_Wrist_Y'].notnull().any():
        top_idx = df['L_Wrist_Y'].idxmin()
        top_frame = df.loc[top_idx, 'Frame']
        addr_df = df[df['Frame'] < top_frame]
        address_frame = df.loc[addr_df['L_Wrist_Y'].idxmax(), 'Frame'] if not addr_df.empty else 0
        imp_df = df[df['Frame'] > top_frame]
        impact_frame = df.loc[imp_df['L_Wrist_Y'].idxmax(), 'Frame'] if not imp_df.empty else frame_count-1
        
        top_data = df.loc[top_idx]
        metrics = {
            'fps': fps,
            'top_frame': int(top_frame),
            'address_frame': int(address_frame),
            'impact_frame': int(impact_frame),
            'head_stability': np.std(nose_x_list) if nose_x_list else 0,
            'spine_angle_top': top_data['Spine_Angle'],
            'knee_angle_top': top_data['R_Knee_Angle'],
            'top_arm_angle': top_data['Arm_Angle']
        }
    else:
        metrics = None

    return output_path, df, metrics

def create_sync_video(pro_path, my_path, pro_metrics, my_metrics, output_path):
    cap_pro = cv2.VideoCapture(pro_path)
    cap_my = cv2.VideoCapture(my_path)
    h_pro = int(cap_pro.get(cv2.CAP_PROP_FRAME_HEIGHT))
    h_my = int(cap_my.get(cv2.CAP_PROP_FRAME_HEIGHT))
    if h_pro == 0 or h_my == 0: return

    target_h = min(h_pro, h_my)
    w_pro = int(cap_pro.get(cv2.CAP_PROP_FRAME_WIDTH))
    w_my = int(cap_my.get(cv2.CAP_PROP_FRAME_WIDTH))
    new_w_pro = int(w_pro * (target_h / h_pro))
    new_w_my = int(w_my * (target_h / h_my))
    target_w = new_w_pro + new_w_my

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, my_metrics['fps'], (target_w, target_h))

    pro_top = pro_metrics['top_frame']
    my_top = my_metrics['top_frame']
    offset = my_top - pro_top
    pro_delay = max(0, offset)
    my_delay = max(0, -offset)
    max_frames = int(max(cap_pro.get(cv2.CAP_PROP_FRAME_COUNT) + pro_delay, 
                         cap_my.get(cv2.CAP_PROP_FRAME_COUNT) + my_delay))

    bar = st.progress(0)
    font = cv2.FONT_HERSHEY_SIMPLEX
    
    for i in range(max_frames):
        if i < pro_delay:
            cap_pro.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret_pro, frame_pro = cap_pro.read()
        else:
            ret_pro, frame_pro = cap_pro.read()
        
        if i < my_delay:
            cap_my.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret_my, frame_my = cap_my.read()
        else:
            ret_my, frame_my = cap_my.read()
            
        if not ret_pro or not ret_my: break

        frame_pro_resized = cv2.resize(frame_pro, (new_w_pro, target_h))
        frame_my_resized = cv2.resize(frame_my, (new_w_my, target_h))
        concat_frame = cv2.hconcat([frame_pro_resized, frame_my_resized])
        
        if i == (pro_top + pro_delay): 
            text_size = cv2.getTextSize("TOP MATCH", font, 1.5, 3)[0]
            tx = (target_w - text_size[0]) // 2
            cv2.putText(concat_frame, "TOP MATCH", (tx, 100), font, 1.5, (0,0,255), 3)
        
        out.write(concat_frame)
        bar.progress((i+1)/max_frames)

    bar.progress(1.0)
    cap_pro.release()
    cap_my.release()
    out.release()
    return

def generate_advice(label, pro_val, my_val):
    diff = my_val - pro_val
    msg = ""
    score = 100
    abs_diff = abs(diff)
    if abs_diff < 5: score = 100
    else: score = max(0, int(100 - abs_diff * 2))

    if label == "Arm":
        if diff < -15: msg = "ãƒ—ãƒ­ã‚ˆã‚Šè‚˜ãŒæ›²ãŒã£ã¦ã„ã¾ã™ã€‚å·¦è…•ã‚’ä¼¸ã°ã™æ„è­˜ã‚’ã€‚"
        elif diff > 10: msg = "è…•ãŒä¼¸ã³ã™ãã¦ã„ã¾ã™ã€‚å°‘ã—ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚’ã€‚"
        else: msg = "ãƒ—ãƒ­åŒæ§˜ã€ç†æƒ³çš„ãªãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚"
    elif label == "Spine":
        if diff < -10: msg = "ãƒ—ãƒ­ã‚ˆã‚Šä¸Šä½“ãŒèµ·ãã¦ã„ã¾ã™ã€‚å‰å‚¾ã‚­ãƒ¼ãƒ—ã€‚"
        elif diff > 10: msg = "å‰å‚¾ãŒæ·±ã™ãã¾ã™ã€‚"
        else: msg = "å‰å‚¾å§¿å‹¢ãŒå®‰å®šã—ã¦ã„ã¾ã™ã€‚"
    elif label == "Knee":
        if diff > 10: msg = "è†ãŒä¼¸ã³ã¦æ£’ç«‹ã¡ã«ãªã£ã¦ã„ã¾ã™ã€‚"
        elif diff < -10: msg = "è†ã‚’æ›²ã’ã™ãã¦ã„ã¾ã™ã€‚"
        else: msg = "è†ã®è§’åº¦ãŒå®‰å®šã—ã¦ã„ã¾ã™ã€‚"
    elif label == "Tempo":
        if my_val < 2.5: msg = "æ‰“ã¡æ€¥ãã§ã™ã€‚ãƒãƒƒã‚¯ã‚¹ã‚¤ãƒ³ã‚°ã‚’ã‚†ã£ãŸã‚Šã€‚"
        elif my_val > 3.5: msg = "å§‹å‹•ãŒé…ã™ãã¾ã™ã€‚ãƒªã‚ºãƒ ã‚ˆãã€‚"
        else: msg = "ç†æƒ³çš„ãªãƒªã‚ºãƒ (3:1)ã§ã™ã€‚"
        score = max(0, int(100 - abs(3.0 - my_val)*30))
    elif label == "Head":
        if my_val > pro_val * 2: msg = "é ­ã®ãƒ–ãƒ¬ãŒå¤§ãã„ã§ã™ã€‚è»¸ã‚’æ„è­˜ã—ã¦ã€‚"
        else: msg = "ä½“å¹¹ãŒå¼·ãã€è»¸ãŒå®‰å®šã—ã¦ã„ã¾ã™ã€‚"
        score = max(0, int(100 - (my_val * 1000)))
    return score, msg

# --- 3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã‚¯ãƒ©ã‚¹ ---
class RealtimeCoach(VideoProcessorBase):
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
        self.mp_drawing = mp.solutions.drawing_utils
        self.target_metrics = None 

    def update_target(self, metrics):
        self.target_metrics = metrics

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1)
        h, w, _ = img.shape
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.pose.process(img_rgb)

        cv2.putText(img, "AI Coach Eye", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200, 200, 200), 1, cv2.LINE_AA)

        if results.pose_landmarks:
            lm = results.pose_landmarks.landmark
            self.mp_drawing.draw_landmarks(
                img, 
                results.pose_landmarks, 
                self.mp_pose.POSE_CONNECTIONS,
                self.mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2),
                self.mp_drawing.DrawingSpec(color=(200,200,200), thickness=1)
            )
            
            l_shoulder = [lm[self.mp_pose.PoseLandmark.LEFT_SHOULDER].x, lm[self.mp_pose.PoseLandmark.LEFT_SHOULDER].y]
            l_elbow = [lm[self.mp_pose.PoseLandmark.LEFT_ELBOW].x, lm[self.mp_pose.PoseLandmark.LEFT_ELBOW].y]
            l_wrist = [lm[self.mp_pose.PoseLandmark.LEFT_WRIST].x, lm[self.mp_pose.PoseLandmark.LEFT_WRIST].y]
            current_arm_angle = calculate_angle(l_shoulder, l_elbow, l_wrist)
            
            if self.target_metrics:
                target_arm = self.target_metrics['top_arm_angle']
                overlay = img.copy()
                cv2.rectangle(overlay, (10, 60), (300, 160), (0,0,0), -1)
                cv2.addWeighted(overlay, 0.6, img, 0.4, 0, img)
                
                cv2.putText(img, f"Current: {int(current_arm_angle)} deg", (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
                cv2.putText(img, f"Target: {int(target_arm)} deg", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1, cv2.LINE_AA)
                
                diff = current_arm_angle - target_arm
                if abs(diff) < 15:
                    cv2.putText(img, "GOOD POSE", (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 100), 2, cv2.LINE_AA)
                
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# --- 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.title("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
selected_club = st.sidebar.selectbox("ã‚¯ãƒ©ãƒ–é¸æŠ", ["ãƒ‰ãƒ©ã‚¤ãƒãƒ¼", "ãƒ•ã‚§ã‚¢ã‚¦ã‚§ã‚¤ã‚¦ãƒƒãƒ‰", "7ç•ªã‚¢ã‚¤ã‚¢ãƒ³", "ã‚¦ã‚§ãƒƒã‚¸", "ãƒ‘ã‚¿ãƒ¼"])
app_mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ["1. ãƒ—ãƒ­å‹•ç”»ç™»éŒ²", "2. ã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­", "3. æ¯”è¼ƒå‹•ç”»ä½œæˆ", "4. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ã‚³ãƒ¼ãƒ"])

# --- 5. äºˆç´„ãƒ»æ¤œç´¢ãƒªãƒ³ã‚¯ (ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆã‚¨ãƒªã‚¢) ---
st.sidebar.markdown("---")
st.sidebar.markdown("##### â›³ ã‚³ãƒ¼ã‚¹ãƒ»ãƒ¬ãƒƒã‚¹ãƒ³äºˆç´„")
st.sidebar.caption("â€»æœ¬ãƒšãƒ¼ã‚¸ã¯ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")

# 1. æ¥½å¤©GORA
rakuten_affiliate_url = "https://hb.afl.rakuten.co.jp/hgc/4fb95961.88417fd4.4fb95962.222603ac/?pc=https%3A%2F%2Fgora.golf.rakuten.co.jp%2F&link_type=text&ut=eyJwYWdlIjoidXJsIiwidHlwZSI6InRleHQiLCJjb2wiOjF9" 

if rakuten_affiliate_url:
    st.sidebar.link_button("ğŸ“… æ¥½å¤©GORAã§äºˆç´„", rakuten_affiliate_url)
else:
    st.sidebar.button("ğŸ“… æ¥½å¤©GORA (è¨­å®šå¾…ã¡)", disabled=True)

# 2. ã˜ã‚ƒã‚‰ã‚“ã‚´ãƒ«ãƒ•
jalan_affiliate_url = "https://px.a8.net/svt/ejp?a8mat=4AUXWQ+EXMG1E+36SI+64C3M"

if jalan_affiliate_url:
    st.sidebar.link_button("ğŸš— ã˜ã‚ƒã‚‰ã‚“ã‚´ãƒ«ãƒ•ã§æ¤œç´¢", jalan_affiliate_url)
else:
    st.sidebar.button("ğŸš— ã˜ã‚ƒã‚‰ã‚“ã‚´ãƒ«ãƒ• (è¨­å®šå¾…ã¡)", disabled=True)

# 3. ãƒ¬ãƒƒã‚¹ãƒ³äºˆç´„
# æ³¨æ„: A8.netã®ãƒªãƒ³ã‚¯ãŒ.gifï¼ˆç”»åƒï¼‰ã«ãªã£ã¦ã„ã‚‹ã€‚ã‚‚ã—ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚‚é£›ã°ãªã„å ´åˆã¯ã€
# A8ç®¡ç†ç”»é¢ã§ã€Œãƒ†ã‚­ã‚¹ãƒˆç´ æã€ã®URL(px.a8.net...)ã‚’å–å¾—ã—ç›´ã—ã¦ãã ã•ã„ã€‚
lesson_affiliate_url = "https://www17.a8.net/0.gif?a8mat=4AUXWQ+F4RNAQ+CW6+BETIUA"

if lesson_affiliate_url:
    st.sidebar.link_button("ğŸ‘¨â€ğŸ« ã‚¹ã‚¯ãƒ¼ãƒ«ã‚’æ¢ã™", lesson_affiliate_url)
else:
    st.sidebar.button("ğŸ‘¨â€ğŸ« ãƒ¬ãƒƒã‚¹ãƒ³ (è¨­å®šå¾…ã¡)", disabled=True)

st.sidebar.markdown("---")
st.sidebar.markdown("""
<div style="font-size: 0.8rem; color: #888;">
    <strong>å…è²¬äº‹é …</strong><br>
    æœ¬ã‚¢ãƒ—ãƒªã®è§£æçµæœã¯AIã«ã‚ˆã‚‹æ¨å®šå€¤ã§ã™ã€‚æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    å‘¨å›²ã®å®‰å…¨ã«ååˆ†é…æ…®ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚
</div>
""", unsafe_allow_html=True)


# --- 6. ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
st.title("K's Golf AI Coach")

# PAGE 1: ãƒ—ãƒ­å‹•ç”»ç™»éŒ²
if app_mode == "1. ãƒ—ãƒ­å‹•ç”»ç™»éŒ²":
    st.header("ãŠæ‰‹æœ¬å‹•ç”»ã®è¨­å®š")
    st.markdown('<div class="info-box">ãƒ—ãƒ­ã®ã‚¹ã‚¤ãƒ³ã‚°å‹•ç”»ã‚’ç™»éŒ²ã—ã¾ã™ã€‚ã‚ãªãŸã®ã‚¹ã‚¤ãƒ³ã‚°ã¨æ¯”è¼ƒã™ã‚‹åŸºæº–ã«ãªã‚Šã¾ã™ã€‚</div>', unsafe_allow_html=True)
    
    if selected_club not in st.session_state['club_data']:
        st.session_state['club_data'][selected_club] = {}

    tab_side, tab_front = st.tabs(["å¾Œæ–¹ (Down-the-line)", "ä½“ã®æ­£é¢ (Face-on)"])
    
    def register_pro_video(angle_key, angle_name):
        current_data = st.session_state['club_data'][selected_club].get(angle_key)
        if current_data:
            st.success(f"âœ… {angle_name}å‹•ç”»: ä¿å­˜æ¸ˆã¿")
            st.video(current_data['video_path'])
            if st.button(f"å‹•ç”»ã‚’å‰Šé™¤", key=f"del_{angle_key}"):
                del st.session_state['club_data'][selected_club][angle_key]
                st.rerun()
        else:
            pro_file = st.file_uploader(f"ãƒ—ãƒ­ã®{angle_name}å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['mp4', 'mov'], key=f"up_{angle_key}")
            pro_rotate = st.selectbox("å›è»¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³", ["ãªã—", "æ™‚è¨ˆå›ã‚Šã«90åº¦", "åæ™‚è¨ˆå›ã‚Šã«90åº¦"], key=f"rot_{angle_key}")
            
            rot_map = {"ãªã—": "ãªã—", "æ™‚è¨ˆå›ã‚Šã«90åº¦": "æ™‚è¨ˆå›ã‚Šã«90åº¦", "åæ™‚è¨ˆå›ã‚Šã«90åº¦": "åæ™‚è¨ˆå›ã‚Šã«90åº¦"}
            
            if pro_file and st.button(f"è§£æã—ã¦ä¿å­˜", key=f"btn_{angle_key}"):
                tfile = tempfile.NamedTemporaryFile(delete=False)
                tfile.write(pro_file.read())
                out_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
                with st.spinner('AIè§£æä¸­...'):
                    processed_path, df, metrics = analyze_video_advanced(tfile.name, out_path, rot_map[pro_rotate])
                    if metrics:
                        st.session_state['club_data'][selected_club][angle_key] = {'video_path': processed_path, 'metrics': metrics}
                        st.success(f"{angle_name}ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                        st.rerun()

    with tab_side:
        register_pro_video('Side', 'å¾Œæ–¹')
    with tab_front:
        register_pro_video('Front', 'ä½“ã®æ­£é¢')

# PAGE 2: ãƒ¦ãƒ¼ã‚¶ãƒ¼è§£æ & ã‚¹ã‚³ã‚¢
elif app_mode == "2. ã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­":
    st.header("ã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­ & ã‚¹ã‚³ã‚¢")

    if selected_club not in st.session_state['club_data'] or not st.session_state['club_data'][selected_club]:
        st.markdown('<div class="warning-box">ãƒ—ãƒ­å‹•ç”»ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€Œãƒ—ãƒ­å‹•ç”»ç™»éŒ²ã€ã‹ã‚‰è¨­å®šã—ã¦ãã ã•ã„ã€‚</div>', unsafe_allow_html=True)
    else:
        available_angles = list(st.session_state['club_data'][selected_club].keys())
        target_angle = st.radio(
            "æ¯”è¼ƒã™ã‚‹ã‚¢ãƒ³ã‚°ãƒ«ã‚’é¸æŠ", 
            available_angles, 
            format_func=lambda x: "ä½“ã®æ­£é¢ (Face-on)" if x=="Front" else "å¾Œæ–¹ (Down-the-line)"
        )
        
        pro_data = st.session_state['club_data'][selected_club][target_angle]
        pm = pro_data['metrics']
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ãŠæ‰‹æœ¬ (Pro)")
            st.video(pro_data['video_path'])
        with col2:
            st.subheader("ã‚ãªãŸ (You)")
            
            warning_msg = "ä½“ã®æ­£é¢ï¼ˆãŠè…¹å´ï¼‰" if target_angle == "Front" else "å¾Œæ–¹ï¼ˆèƒŒä¸­å´ï¼‰"
            st.markdown(f"""
            <div class="info-box">
                æ’®å½±ã®ãƒ’ãƒ³ãƒˆ: æ­£ç¢ºãªã‚¹ã‚³ã‚¢ã‚’å‡ºã™ãŸã‚ã€ãƒ—ãƒ­ã¨åŒã˜ <strong>ã€Œ{warning_msg}ã€</strong> ã‹ã‚‰æ’®å½±ã—ã¦ãã ã•ã„ã€‚
            </div>
            """, unsafe_allow_html=True)

            my_file = st.file_uploader("è‡ªåˆ†ã®å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['mp4', 'mov'])
            my_rotate = st.selectbox("å›è»¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³", ["ãªã—", "æ™‚è¨ˆå›ã‚Šã«90åº¦", "åæ™‚è¨ˆå›ã‚Šã«90åº¦"])
            rot_map = {"ãªã—": "ãªã—", "æ™‚è¨ˆå›ã‚Šã«90åº¦": "æ™‚è¨ˆå›ã‚Šã«90åº¦", "åæ™‚è¨ˆå›ã‚Šã«90åº¦": "åæ™‚è¨ˆå›ã‚Šã«90åº¦"}
            
            if my_file and st.button("è¨ºæ–­é–‹å§‹"):
                tfile = tempfile.NamedTemporaryFile(delete=False)
                tfile.write(my_file.read())
                out_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
                with st.spinner('ç¾åœ¨è§£æä¸­... AIãŒã‚¹ã‚¤ãƒ³ã‚°ã‚’åˆ†æã—ã¦ã„ã¾ã™'):
                    processed_path, df, metrics = analyze_video_advanced(tfile.name, out_path, rot_map[my_rotate])
                    st.session_state['my_processed_video'] = processed_path
                    st.session_state['my_metrics'] = metrics
                st.rerun()

            if st.session_state['my_processed_video']:
                st.video(st.session_state['my_processed_video'])

        if st.session_state['my_metrics']:
            mm = st.session_state['my_metrics']
            m_back = mm['top_frame'] - mm['address_frame']
            m_down = mm['impact_frame'] - mm['top_frame']
            my_tempo = m_back / m_down if m_down > 0 else 0
            
            s_arm, m_arm = generate_advice("Arm", pm['top_arm_angle'], mm['top_arm_angle'])
            s_spine, m_spine = generate_advice("Spine", pm['spine_angle_top'], mm['spine_angle_top'])
            s_knee, m_knee = generate_advice("Knee", pm['knee_angle_top'], mm['knee_angle_top'])
            s_tempo, m_tempo = generate_advice("Tempo", 3.0, my_tempo)
            s_head, m_head = generate_advice("Head", pm['head_stability'], mm['head_stability'])

            total_score = int((s_arm + s_spine + s_knee + s_tempo + s_head) / 5)

            st.markdown("---")
            st.markdown(f"""
            <div class="minimal-card">
                <div class="score-title">TOTAL SCORE</div>
                <div class="total-score-val">{total_score}</div>
            </div>
            """, unsafe_allow_html=True)

            c1, c2, c3, c4, c5 = st.columns(5)
            def show_card(col, title, score, msg):
                with col:
                    st.markdown(f"""
                    <div class="minimal-card" style="padding: 16px; margin-bottom: 10px;">
                        <div class="score-title">{title}</div>
                        <div class="metric-val">{score}</div>
                        <div class="advice-text">{msg}</div>
                    </div>
                    """, unsafe_allow_html=True)

            show_card(c1, "ãƒ†ãƒ³ãƒ", s_tempo, m_tempo)
            show_card(c2, "å·¦è…•ã®ä¼¸ã³", s_arm, m_arm)
            show_card(c3, "é ­ã®å›ºå®š", s_head, m_head)
            show_card(c4, "å‰å‚¾ç¶­æŒ", s_spine, m_spine)
            show_card(c5, "è†ã®ç²˜ã‚Š", s_knee, m_knee)

# PAGE 3: æ¯”è¼ƒå‹•ç”» (Sync)
elif app_mode == "3. æ¯”è¼ƒå‹•ç”»ä½œæˆ":
    st.header("åŒæœŸå‹•ç”»ä½œæˆ")
    
    if selected_club in st.session_state['club_data'] and st.session_state['my_metrics']:
        available_angles = list(st.session_state['club_data'][selected_club].keys())
        target_angle = st.radio(
            "çµåˆã™ã‚‹ãƒ—ãƒ­å‹•ç”»ã®ã‚¢ãƒ³ã‚°ãƒ«", 
            available_angles, 
            format_func=lambda x: "ä½“ã®æ­£é¢ (Face-on)" if x=="Front" else "å¾Œæ–¹ (Down-the-line)"
        )
        
        if st.button("æ¯”è¼ƒå‹•ç”»ã‚’ç”Ÿæˆ"):
            sync_out = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
            with st.spinner("å‡¦ç†ä¸­... ãƒˆãƒƒãƒ—ä½ç½®ã§ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’åˆã‚ã›ã¦ã„ã¾ã™"):
                pro_path = st.session_state['club_data'][selected_club][target_angle]['video_path']
                my_path = st.session_state['my_processed_video']
                
                create_sync_video(
                    pro_path, 
                    my_path, 
                    st.session_state['club_data'][selected_club][target_angle]['metrics'],
                    st.session_state['my_metrics'],
                    sync_out
                )
                st.session_state['sync_video_path'] = sync_out
            st.success("å®Œæˆã—ã¾ã—ãŸï¼")
            
        if st.session_state['sync_video_path']:
            st.video(st.session_state['sync_video_path'])
    else:
        st.markdown('<div class="warning-box">è§£æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€Œã‚¹ã‚¤ãƒ³ã‚°è¨ºæ–­ã€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚</div>', unsafe_allow_html=True)

# PAGE 4: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ã‚³ãƒ¼ãƒ
elif app_mode == "4. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ã‚³ãƒ¼ãƒ":
    st.header("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»AIã‚³ãƒ¼ãƒ")
    st.write("ã‚«ãƒ¡ãƒ©ã«å‘ã‹ã£ã¦æ§‹ãˆã¦ãã ã•ã„ã€‚")

    st.markdown('<div class="warning-box">å®‰å…¨è­¦å‘Šï¼šæ‰“çƒã®é€²è¡Œæ–¹å‘ã«ã¯çµ¶å¯¾ã«ç«‹ãŸãªã„ã§ãã ã•ã„ã€‚</div>', unsafe_allow_html=True)

    if selected_club not in st.session_state['club_data'] or not st.session_state['club_data'][selected_club]:
         st.markdown('<div class="warning-box">ãƒ—ãƒ­å‹•ç”»ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚</div>', unsafe_allow_html=True)
    else:
        available_angles = list(st.session_state['club_data'][selected_club].keys())
        target_angle = st.radio(
            "ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚¢ãƒ³ã‚°ãƒ«", 
            available_angles, 
            format_func=lambda x: "ä½“ã®æ­£é¢ (Face-on)" if x=="Front" else "å¾Œæ–¹ (Down-the-line)"
        )
        
        target_metrics = st.session_state['club_data'][selected_club][target_angle]['metrics']
        
        ctx = webrtc_streamer(
            key="realtime-coach", 
            mode=WebRtcMode.SENDRECV, 
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            video_processor_factory=RealtimeCoach,
            async_processing=True
        )
        
        if ctx.video_processor:
            ctx.video_processor.update_target(target_metrics)
