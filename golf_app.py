import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import av
import tempfile
import pandas as pd
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode

# --- 1. åŸºæœ¬è¨­å®š ---
st.set_page_config(layout="wide", page_title="K's Golf AI Coach")

st.markdown("""
    <style>
    .main > div {padding-top: 2rem;}
    </style>
    """, unsafe_allow_html=True)

# --- Session State (è¨˜æ†¶é ˜åŸŸ) ã®åˆæœŸåŒ– ---
if 'pro_processed_video' not in st.session_state:
    st.session_state['pro_processed_video'] = None
if 'pro_df' not in st.session_state:
    st.session_state['pro_df'] = None
if 'my_processed_video' not in st.session_state:
    st.session_state['my_processed_video'] = None
if 'my_df' not in st.session_state:
    st.session_state['my_df'] = None

# --- 2. è¨ˆç®—ç”¨é–¢æ•° ---

def calculate_angle(a, b, c):
    """3ç‚¹ã®åº§æ¨™ã‹ã‚‰è§’åº¦ã‚’è¨ˆç®—"""
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0:
        angle = 360-angle
    return angle

def analyze_video(input_path, output_path):
    """å‹•ç”»è§£æï¼†ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆãƒˆãƒƒãƒ—ä½ç½®æ¤œå‡ºç”¨ã«æ‰‹é¦–Yåº§æ¨™ã‚‚ä¿å­˜ï¼‰"""
    cap = cv2.VideoCapture(input_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    
    pose_data = []
    
    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        bar = st.progress(0)
        
        for i in range(frame_count):
            ret, frame = cap.read()
            if not ret:
                break
            
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False
            results = pose.process(image)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            
            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark
                
                # åº§æ¨™å–å¾—
                l_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                l_elbow    = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                l_wrist    = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]
                l_hip      = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]

                angle = calculate_angle(l_shoulder, l_elbow, l_wrist)
                
                # â˜…ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ (ãƒˆãƒƒãƒ—æ¤œå‡ºã®ãŸã‚ã«Wrist_Yã‚’è¿½åŠ )
                pose_data.append({
                    "Frame": i,
                    "Time_Sec": i / fps if fps > 0 else 0,
                    "Arm_Angle": angle,
                    "L_Shoulder_X": l_shoulder[0],
                    "L_Shoulder_Y": l_shoulder[1],
                    "L_Wrist_Y": l_wrist[1],  # Yåº§æ¨™ãŒå°ã•ã„ã»ã©é«˜ã„ä½ç½®
                    "L_Hip_X": l_hip[0],
                    "L_Hip_Y": l_hip[1]
                })

                # æç”»ç”¨åˆ¤å®š
                if angle > 160:
                    color = (0, 255, 0)
                    stage = "Good!"
                else:
                    color = (0, 0, 255)
                    stage = "Bad"

                mp_drawing.draw_landmarks(
                    image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=4),
                    mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2)
                )

                cv2.rectangle(image, (0,0), (image.shape[1], 50), color, -1)
                cv2.putText(image, f'{stage} Angle: {int(angle)}', (10,35), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255), 2, cv2.LINE_AA)

            out.write(image)
            if frame_count > 0:
                bar.progress((i + 1) / frame_count)

    cap.release()
    out.release()
    df = pd.DataFrame(pose_data)
    return output_path, df

# --- 3. æ˜ åƒå‡¦ç†ã‚¯ãƒ©ã‚¹ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ï¼‰ ---
class PoseProcessor(VideoProcessorBase):
    def __init__(self):
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = self.pose.process(image)
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            shoulder = [landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
            elbow = [landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
            wrist = [landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value].y]
            
            angle = calculate_angle(shoulder, elbow, wrist)
            
            if angle > 160:
                color = (0, 255, 0)
                stage = "Good!"
            else:
                color = (0, 0, 255)
                stage = "Bad"

            self.mp_drawing.draw_landmarks(
                image, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
                self.mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=4),
                self.mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2)
            )

            cv2.rectangle(image, (0,0), (image.shape[1], 50), color, -1)
            cv2.putText(image, f'{stage} Angle: {int(angle)}', (10,35), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)

        return av.VideoFrame.from_ndarray(image, format="bgr24")

# --- 4. ã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³æ§‹é€  ---
st.title("â›³ï¸ K's Golf AI Coach")

st.sidebar.header("ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
app_mode = st.sidebar.selectbox("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š (Real-time)", "å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ†æ (Upload)"])
st.sidebar.divider()
club_list = ["ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ (1W)", "ã‚¢ã‚¤ã‚¢ãƒ³ (7I)", "ã‚¦ã‚§ãƒƒã‚¸", "ãƒ‘ã‚¿ãƒ¼"]
club_select = st.sidebar.selectbox("ä½¿ç”¨ã‚¯ãƒ©ãƒ–", club_list)


# --- ãƒ¢ãƒ¼ãƒ‰A: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š ---
if app_mode == "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š (Real-time)":
    st.header("âš¡ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ã‚³ãƒ¼ãƒ")
    col1, col2 = st.columns(2)
    with col1:
        st.info("ğŸ‘ˆ ãƒ—ãƒ­ã®ãŠæ‰‹æœ¬å‹•ç”»")
        st.image("https://via.placeholder.com/360x640.png?text=Pro+Swing", use_container_width=True)
    with col2:
        st.success("ğŸ“¸ ã‚«ãƒ¡ãƒ©æ˜ åƒ")
        webrtc_streamer(
            key="golf-pose-realtime",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=PoseProcessor,
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )

# --- ãƒ¢ãƒ¼ãƒ‰B: å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ†æ ---
elif app_mode == "å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ†æ (Upload)":
    st.header("ğŸ“‚ å‹•ç”»åˆ†æãƒ©ãƒœ")
    
    # â˜…æ³¨æ„æ›¸ãã®è¿½åŠ  (é‡è¦ï¼)
    st.warning("âš ï¸ **é‡è¦:** æ­£ç¢ºãªæ¯”è¼ƒã®ãŸã‚ã€**ãƒ—ãƒ­ã®å‹•ç”»ã¨ã€ŒåŒã˜ã‚¢ãƒ³ã‚°ãƒ«ï¼ˆæ­£é¢/å¾Œæ–¹ï¼‰ã€** ã§æ’®å½±ã•ã‚ŒãŸå‹•ç”»ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚ã‚¢ãƒ³ã‚°ãƒ«ãŒç•°ãªã‚‹ã¨AIãŒæ­£ã—ãåˆ¤å®šã§ãã¾ã›ã‚“ã€‚")

    col1, col2 = st.columns(2)
    
    # --- å·¦ã‚«ãƒ©ãƒ : ãƒ—ãƒ­ ---
    with col1:
        st.subheader("1. ãƒ—ãƒ­/ãŠæ‰‹æœ¬ã®å‹•ç”»")
        pro_video = st.file_uploader("ãƒ—ãƒ­ã®å‹•ç”»", type=['mp4', 'mov'], key="pro_video")
        
        if pro_video is not None:
            st.video(pro_video)
            if st.button("ğŸ” ãƒ—ãƒ­å‹•ç”»ã‚’è§£æ"):
                tfile = tempfile.NamedTemporaryFile(delete=False) 
                tfile.write(pro_video.read())
                output_pro = tfile.name + "_pro_processed.mp4"
                
                with st.spinner("ãƒ—ãƒ­è§£æä¸­..."):
                    path, df = analyze_video(tfile.name, output_pro)
                    st.session_state['pro_processed_video'] = path
                    st.session_state['pro_df'] = df
                    st.success("è§£æå®Œäº†ï¼")

            if st.session_state['pro_processed_video']:
                st.write("---")
                st.video(st.session_state['pro_processed_video'])
                csv = st.session_state['pro_df'].to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ ãƒ—ãƒ­ã®CSV DL", csv, 'pro_data.csv', 'text/csv')

    # --- å³ã‚«ãƒ©ãƒ : è‡ªåˆ† ---
    with col2:
        st.subheader("2. ã‚ãªãŸã®ã‚¹ã‚¤ãƒ³ã‚°å‹•ç”»")
        my_video = st.file_uploader("è‡ªåˆ†ã®å‹•ç”»", type=['mp4', 'mov'], key="my_video")
        
        if my_video is not None:
            if st.button("ğŸš€ è‡ªåˆ†ã®å‹•ç”»ã‚’è§£æ"):
                tfile = tempfile.NamedTemporaryFile(delete=False) 
                tfile.write(my_video.read())
                output_my = tfile.name + "_my_processed.mp4"
                
                with st.spinner("è‡ªåˆ†è§£æä¸­..."):
                    path, df = analyze_video(tfile.name, output_my)
                    st.session_state['my_processed_video'] = path
                    st.session_state['my_df'] = df
                    st.success("è§£æå®Œäº†ï¼")

            if st.session_state['my_processed_video']:
                st.write("---")
                st.video(st.session_state['my_processed_video'])
                csv_my = st.session_state['my_df'].to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ è‡ªåˆ†ã®CSV DL", csv_my, 'my_data.csv', 'text/csv')

    # --- â˜…æ¯”è¼ƒè¨ºæ–­ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ãŸã‚‰è¡¨ç¤º) ---
    if st.session_state['pro_df'] is not None and st.session_state['my_df'] is not None:
        st.divider()
        st.header("ğŸ¤– AIã‚³ãƒ¼ãƒã®è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ")
        
        # 1. ãƒˆãƒƒãƒ—ä½ç½®ï¼ˆæ‰‹é¦–ãŒä¸€ç•ªé«˜ã„ä½ç½®ï¼‰ã‚’æ¢ã™
        # L_Wrist_Y ã¯ç”»é¢ä¸ŠãŒ0ã€ä¸‹ãŒ1ãªã®ã§ã€æœ€å°å€¤ãŒä¸€ç•ªé«˜ã„ä½ç½®
        pro_df = st.session_state['pro_df']
        my_df = st.session_state['my_df']
        
        # ãƒ—ãƒ­ã®ãƒˆãƒƒãƒ—
        pro_top_idx = pro_df['L_Wrist_Y'].idxmin()
        pro_top_angle = pro_df.iloc[pro_top_idx]['Arm_Angle']
        
        # è‡ªåˆ†ã®ãƒˆãƒƒãƒ—
        my_top_idx = my_df['L_Wrist_Y'].idxmin()
        my_top_angle = my_df.iloc[my_top_idx]['Arm_Angle']
        
        # 2. æ¯”è¼ƒçµæœã®è¡¨ç¤º
        col_res1, col_res2, col_res3 = st.columns(3)
        col_res1.metric("ãƒ—ãƒ­ã®ãƒˆãƒƒãƒ—æ™‚ å·¦è‚˜è§’åº¦", f"{int(pro_top_angle)}Â°")
        col_res2.metric("ã‚ãªãŸã®ãƒˆãƒƒãƒ—æ™‚ å·¦è‚˜è§’åº¦", f"{int(my_top_angle)}Â°")
        
        diff = my_top_angle - pro_top_angle
        col_res3.metric("å·®åˆ†", f"{int(diff)}Â°", delta=-diff) # å·®ãŒå¤§ãã„ã¨èµ¤ããªã‚‹ã‚ˆã†ã«è¨­å®š

        # 3. ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆ
        st.subheader("ğŸ’¡ ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆãƒ»ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
        if abs(diff) < 15:
            st.success("ç´ æ™´ã‚‰ã—ã„ï¼ãƒ—ãƒ­ã¨ã»ã¼åŒã˜è‚˜ã®ä¼¸ã³å…·åˆã§ã™ã€‚ã“ã®èª¿å­ã§ã‚­ãƒ¼ãƒ—ã—ã¾ã—ã‚‡ã†ï¼")
        elif diff > 15:
            st.error("è‚˜ãŒæ›²ãŒã‚Šã™ãã¦ã„ã¾ã™ï¼ˆãƒã‚­ãƒ³ã‚¦ã‚£ãƒ³ã‚°æ°—å‘³ï¼‰ã€‚ãƒˆãƒƒãƒ—ã§ã‚‚ã†å°‘ã—è…•ã‚’ä¼¸ã°ã™æ„è­˜ã‚’æŒã¡ã¾ã—ã‚‡ã†ã€‚")
        else:
            st.warning("è‚˜ãŒä¼¸ã³ã™ãã¦ç¡¬ããªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚‚ã†å°‘ã—ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")
